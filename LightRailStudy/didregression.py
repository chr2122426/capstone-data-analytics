# -*- coding: utf-8 -*-
"""DIDRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JnFWj7BHeGTkXka_B7J-YeMcY968RI6-
"""

import numpy as np
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

data = pd.read_csv('Final_lightRail_dataset.csv')
df = pd.DataFrame(data)

print(df.info())

df.dropna(inplace=True)

df = df[df['Establishment_Sector'] != 'Total_Establishments'].copy()

treatment_zips = df[df['Adjacency_Indicator'] == 1]['ZIP'].unique()
df['Treatment_Group'] = df['ZIP'].isin(treatment_zips).astype(int)

df['DID_Impl'] = df['Treatment_Group'] * df['Impl_phase_Indicator']
df['DID_Post'] = df['Treatment_Group'] * df['Post_Impl_Indicator']

df['Time'] = df['Year'] - 2000

def fit_ols_cluster(formula, data, cluster_col='ZIP'):
    """Fits OLS model with clustered standard errors."""
    model = smf.ols(formula=formula, data=data)
    res = model.fit(cov_type='cluster', cov_kwds={'groups': data[cluster_col]})
    return res

def analyze_did_model(res, outcome_name):
    """Prints summary, joint test, and comparison test for DID results."""
    print(f"\nAnalysis: {outcome_name}")
    print(res.summary())

    did_terms = ['DID_Impl', 'DID_Post']

    # Joint Test
    restrictions = ','.join([f"{t} = 0" for t in did_terms])
    ftest = res.f_test(restrictions)
    print("\nJoint Test (Impl and Post)")
    print(ftest)

    # Comparison Test
    print("\nComparison Test (Post vs Impl)")
    restrictions = "DID_Post - DID_Impl = 0"
    t_test = res.t_test(restrictions)
    print(t_test)

group_time_trend = 'Treatment_Group:Time'
# Define controls once
controls = 'COVID_Indicator + Crisis2008_Indicator'
# Base formula with Fixed Effects
base_formula = f'DID_Impl + DID_Post + {controls} + C(ZIP) + C(Year) + {group_time_trend}'

outcomes = {
    'Log_Median_Value': 'A1: Log_Median_Value (Testing H0a)',
    'Log_HPI': 'A2: Log_HPI (Robustness Check)',
    'Log_Business_Density': 'B: Log_Business_Density (Testing H0b)'
}

results_did = {}

for dep_var, title in outcomes.items():
    formula = f'{dep_var} ~ {base_formula}'
    res = fit_ols_cluster(formula, df)
    results_did[dep_var] = res
    analyze_did_model(res, title)

df['Establishment_Sector'] = df['Establishment_Sector'].replace({'etail_Trade': 'Retail_Trade'})

hypothesis_sectors = ['Retail_Trade', 'Accommodation_Food_Services']
reference_sector = 'Professional_Services'

df_h1d = df[
    df['Establishment_Sector'].isin(hypothesis_sectors + [reference_sector])
].copy()

# create Dummy variables
df_h1d['Retail_Dummy'] = (df_h1d['Establishment_Sector'] == 'Retail_Trade').astype(int)
df_h1d['Food_Service_Dummy'] = (df_h1d['Establishment_Sector'] == 'Accommodation_Food_Services').astype(int)

df_h1d['DDD_Retail_Impl'] = df_h1d['DID_Impl'] * df_h1d['Retail_Dummy']
df_h1d['DDD_Retail_Post'] = df_h1d['DID_Post'] * df_h1d['Retail_Dummy']
df_h1d['DDD_Food_Impl'] = df_h1d['DID_Impl'] * df_h1d['Food_Service_Dummy']
df_h1d['DDD_Food_Post'] = df_h1d['DID_Post'] * df_h1d['Food_Service_Dummy']

# define formula_h1d
formula_h1d = (
    'Log_Business_Density ~ '
    'Retail_Dummy + Food_Service_Dummy + '
    'DDD_Retail_Impl + DDD_Retail_Post + '
    'DDD_Food_Impl + DDD_Food_Post + '
    f'{controls} + C(ZIP) + C(Year)'
)


res_h1d = fit_ols_cluster(formula_h1d, df_h1d)
print("\nDDD Model: Retail & Food Service vs. Professional Services")
print(res_h1d.summary())
h1d_terms = ['DDD_Retail_Impl', 'DDD_Retail_Post', 'DDD_Food_Impl', 'DDD_Food_Post']

#joint test logic
restrictions = ','.join([f"{t} = 0" for t in h1d_terms])
ftest = res_h1d.f_test(restrictions)
print("\nJoint test for DDD Terms")
print(ftest)

results_table = res_h1d.summary().tables[1]
df_results = pd.DataFrame(results_table.data[1:], columns=results_table.data[0])
df_results.to_csv("DDD_Coefficients_Table.csv", index=False)

sns.set(style="whitegrid")

# Configuration (Corrected Impl Year to 2009 for plot visualization)
outcome = 'Log_Median_Value'
impl_start_year = 2009 # First year of the Implementation Phase (2009-2016)
group_labels = {0: 'Control', 1: 'Treated'}

# Compute yearly averages by treatment group
trend_df = (
    df.groupby(['Year', 'Treatment_Group'])[outcome]
    .mean()
    .reset_index()
)
trend_df['Group'] = trend_df['Treatment_Group'].map(group_labels)

# Plot
plt.figure(figsize=(8, 5))
sns.lineplot(
    data=trend_df,
    x='Year',
    y=outcome,
    hue='Group',
    marker='o',
    linewidth=2.5
)

# Add vertical line for implementation start
plt.axvline(impl_start_year, color='red', linestyle='--', label=f'Treatment Begins ({impl_start_year})')

# Titles and labels
plt.title(f"Parallel Trends: {outcome}")
plt.xlabel("Year")
plt.ylabel(f"Mean {outcome}")
plt.legend(title='Group', loc='best')
plt.tight_layout()
plt.show()

# Extract coefficients and confidence intervals from the statsmodels result
coef = results_did['Log_Median_Value'].params
conf = results_did['Log_Median_Value'].conf_int()
conf.columns = ['CI_lower', 'CI_upper']

# Combine into one DataFrame
results = pd.concat([coef, conf], axis=1).reset_index()
results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']

# Filter to focus on DID variables only
did_results = results[results['Variable'].isin(['DID_Impl', 'DID_Post'])]

# Plot
plt.figure(figsize=(7, 3.5))
sns.set(style="whitegrid")

plt.errorbar(
    did_results['Coefficient'],
    did_results['Variable'],
    xerr=[
        did_results['Coefficient'] - did_results['CI_lower'],
        did_results['CI_upper'] - did_results['Coefficient']
    ],
    fmt='o', color='blue', ecolor='gray', capsize=4, markersize=8
)
plt.axvline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients with 95% Confidence Intervals (Log_Median_Value)")
plt.xlabel("Coefficient Estimate")
plt.ylabel("Variable")
plt.tight_layout()
plt.show()
did_results.to_csv("A1_Coefficients.csv", index=False)

sns.set(style="whitegrid")

res = results_did['Log_Median_Value'] # Use the Log_Median_Value result

# 1. Prepare Data
did_vars = ['DID_Impl', 'DID_Post'] # Corrected variable names
coef = res.params[did_vars]
conf = res.conf_int().loc[did_vars]
conf.columns = ['CI_lower', 'CI_upper']

did_results = pd.concat([coef, conf], axis=1).reset_index()
did_results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']

# Calculate error bar size
did_results['CI_error'] = did_results['CI_upper'] - did_results['Coefficient']
did_results['Variable'] = did_results['Variable'].replace({
    'DID_Impl': 'Implementation Phase',
    'DID_Post': 'Post-Implementation Phase'
})

# 2. Plot
plt.figure(figsize=(8, 5))
sns.barplot(
    x='Variable',
    y='Coefficient',
    data=did_results,
    color='skyblue',
    # Use the calculated CI_error for the yerr argument in the bar plot
    yerr=did_results['CI_error'].values
)

plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients for Log_Median_Value (vs. Pre-Impl)")
plt.xlabel("Intervention Phase")
plt.ylabel("Coefficient Estimate (Log Change)")
plt.tight_layout()
plt.show()

sns.set(style="whitegrid")

# Configuration
outcome = 'Log_HPI'
impl_start_year = 2009
group_labels = {0: 'Control', 1: 'Treated'}

# Compute yearly averages by treatment group
trend_df = (
    df.groupby(['Year', 'Treatment_Group'])[outcome]
    .mean()
    .reset_index()
)
trend_df['Group'] = trend_df['Treatment_Group'].map(group_labels)

# Plot
plt.figure(figsize=(8, 5))
sns.lineplot(
    data=trend_df,
    x='Year',
    y=outcome,
    hue='Group',
    marker='o',
    linewidth=2.5
)

# Add vertical line for implementation start
plt.axvline(impl_start_year, color='red', linestyle='--', label=f'Treatment Begins ({impl_start_year})')

# Titles and labels
plt.title(f"Parallel Trends: {outcome}")
plt.xlabel("Year")
plt.ylabel(f"Mean {outcome}")
plt.legend(title='Group', loc='best')
plt.tight_layout()
plt.show()

# Extract coefficients and confidence intervals from the statsmodels result
coef = results_did['Log_HPI'].params
conf = results_did['Log_HPI'].conf_int()
conf.columns = ['CI_lower', 'CI_upper']

# Combine into one DataFrame
results = pd.concat([coef, conf], axis=1).reset_index()
results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']

# Filter to focus on DID variables only
did_results = results[results['Variable'].isin(['DID_Impl', 'DID_Post'])]

# Plot
plt.figure(figsize=(7, 3.5))
sns.set(style="whitegrid")

plt.errorbar(
    did_results['Coefficient'],
    did_results['Variable'],
    xerr=[
        did_results['Coefficient'] - did_results['CI_lower'],
        did_results['CI_upper'] - did_results['Coefficient']
    ],
    fmt='o', color='blue', ecolor='gray', capsize=4, markersize=8
)
plt.axvline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients with 95% Confidence Intervals (Log_HPI (robustness))")
plt.xlabel("Coefficient Estimate")
plt.ylabel("Variable")
plt.tight_layout()
plt.show()
did_results.to_csv("A2_Coefficients.csv", index=False)

sns.set(style="whitegrid")

res = results_did['Log_HPI']

# Prepare Data
did_vars = ['DID_Impl', 'DID_Post']
coef = res.params[did_vars]
conf = res.conf_int().loc[did_vars]
conf.columns = ['CI_lower', 'CI_upper']

did_results = pd.concat([coef, conf], axis=1).reset_index()
did_results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']

# Calculate error bar size
did_results['CI_error'] = did_results['CI_upper'] - did_results['Coefficient']
did_results['Variable'] = did_results['Variable'].replace({
    'DID_Impl': 'Implementation Phase',
    'DID_Post': 'Post-Implementation Phase'
})

# Plot
plt.figure(figsize=(8, 5))
sns.barplot(
    x='Variable',
    y='Coefficient',
    data=did_results,
    color='lightcoral',
    yerr=did_results['CI_error'].values
)

plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients for Log_HPI (vs. Pre-Impl)")
plt.xlabel("Intervention Phase")
plt.ylabel("Coefficient Estimate (Log Change)")
plt.tight_layout()
plt.show()

# Extract coefficients and confidence intervals from the statsmodels result
coef = results_did['Log_Business_Density'].params
conf = results_did['Log_Business_Density'].conf_int()
conf.columns = ['CI_lower', 'CI_upper']

# Combine into one DataFrame
results = pd.concat([coef, conf], axis=1).reset_index()
results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']


# Filter to focus on DID variables only
did_results = results[results['Variable'].isin(['DID_Impl', 'DID_Post'])]

# Plot
plt.figure(figsize=(7, 3.5))
sns.set(style="whitegrid")

plt.errorbar(
    did_results['Coefficient'],
    did_results['Variable'],
    xerr=[
        did_results['Coefficient'] - did_results['CI_lower'],
        did_results['CI_upper'] - did_results['Coefficient']
    ],
    fmt='o', color='blue', ecolor='gray', capsize=4, markersize=8
)
plt.axvline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients with 95% Confidence Intervals (Log_Business_Density)")
plt.xlabel("Coefficient Estimate")
plt.ylabel("Intervention Phase") # Changed label for clarity
plt.yticks([0, 1], ['Implementation Phase', 'Post-Implementation Phase']) # Map variable names to clearer labels
plt.tight_layout()
plt.show()
did_results.to_csv("B_Coefficients.csv", index=False)

sns.set(style="whitegrid")

# Configuration
outcome = 'Log_Business_Density'
impl_start_year = 2009
group_labels = {0: 'Control', 1: 'Treated'}

# Compute yearly averages by treatment group
trend_df = (
    df.groupby(['Year', 'Treatment_Group'])[outcome]
    .mean()
    .reset_index()
)
trend_df['Group'] = trend_df['Treatment_Group'].map(group_labels)

# Plot
plt.figure(figsize=(8, 5))
sns.lineplot(
    data=trend_df,
    x='Year',
    y=outcome,
    hue='Group',
    marker='o',
    linewidth=2.5
)

# Add vertical line for implementation start
plt.axvline(impl_start_year, color='red', linestyle='--', label=f'Treatment Begins ({impl_start_year})')

# Titles and labels
plt.title(f"Parallel Trends: {outcome}")
plt.xlabel("Year")
plt.ylabel(f"Mean {outcome}")
plt.legend(title='Group', loc='best')
plt.tight_layout()
plt.show()

sns.set(style="whitegrid")

res = results_did['Log_Business_Density'] # Use the Log_Business_Density result

# Prepare Data
did_vars = ['DID_Impl', 'DID_Post']
coef = res.params[did_vars]
conf = res.conf_int().loc[did_vars]
conf.columns = ['CI_lower', 'CI_upper']

did_results = pd.concat([coef, conf], axis=1).reset_index()
did_results.columns = ['Variable', 'Coefficient', 'CI_lower', 'CI_upper']

# Calculate error bar size
did_results['CI_error'] = did_results['CI_upper'] - did_results['Coefficient']
did_results['Variable'] = did_results['Variable'].replace({
    'DID_Impl': 'Implementation Phase',
    'DID_Post': 'Post-Implementation Phase'
})

# 2. Plot
plt.figure(figsize=(8, 5))
sns.barplot(
    x='Variable',
    y='Coefficient',
    data=did_results,
    color='lightgreen',
    yerr=did_results['CI_error'].values
)

plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.title("DID Coefficients for Log_Business_Density (vs. Pre-Impl)")
plt.xlabel("Intervention Phase")
plt.ylabel("Coefficient Estimate (Log Change)")
plt.tight_layout()
plt.show()

#  Define the relevant DDD terms for the POST phase
post_ddd_terms = ['DDD_Retail_Post', 'DDD_Food_Post']

# Extract coefficients and confidence intervals from the result object (res_h1d)
coef = res_h1d.params[post_ddd_terms]
conf = res_h1d.conf_int().loc[post_ddd_terms]
conf.columns = ['CI_lower', 'CI_upper']
bse = res_h1d.bse[post_ddd_terms]

#Combine into a single DataFrame for plotting
ddd_post_results = pd.concat([coef, conf, bse], axis=1).reset_index()
ddd_post_results.columns = ['Term', 'Coefficient', 'CI_lower', 'CI_upper', 'StdErr']

# Clean up names for better plotting labels
ddd_post_results['Sector'] = ddd_post_results['Term'].str.replace('DDD_', '').str.replace('_Post', '').str.replace('_', ' ')

# Calculate error bar size (difference between coefficient and CI bounds)
ddd_post_results['Error_Size'] = ddd_post_results['CI_upper'] - ddd_post_results['Coefficient']

#Plot the results
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")

# Use plt.errorbar to create the scatter plot with CIs
plt.errorbar(
    ddd_post_results['Sector'],
    ddd_post_results['Coefficient'],
    # xerr: horizontal error, yerr: vertical error
    yerr=[
        ddd_post_results['Coefficient'] - ddd_post_results['CI_lower'],
        ddd_post_results['CI_upper'] - ddd_post_results['Coefficient']
    ],
    fmt='o',
    capsize=5,
    color='blue',
    ecolor='gray',
    markersize=8
)

plt.axhline(0, color='red', linestyle='--', linewidth=1, label='No effect line')
plt.xticks(rotation=45, ha='right')
plt.title('Differential Effect of Light Rail (Post-Implementation) vs. Professional Services')
plt.ylabel('DDD Coefficient Estimate (Log Change)')
plt.xlabel('Sector')
plt.legend()
plt.tight_layout()
plt.show()

#Define ALL relevant DDD terms
all_ddd_terms = ['DDD_Retail_Impl', 'DDD_Retail_Post', 'DDD_Food_Impl', 'DDD_Food_Post']

#Extract and Combine Data
coef = res_h1d.params[all_ddd_terms]
conf = res_h1d.conf_int().loc[all_ddd_terms]
conf.columns = ['CI_lower', 'CI_upper']

ddd_full_results = pd.concat([coef, conf], axis=1).reset_index()
ddd_full_results.columns = ['Term', 'Coefficient', 'CI_lower', 'CI_upper']

# Create Categorical Variables for Plotting
ddd_full_results['Sector'] = ddd_full_results['Term'].str.split('_').str[1]
ddd_full_results['Phase'] = ddd_full_results['Term'].str.split('_').str[2]
ddd_full_results['Label'] = ddd_full_results['Sector'] + ' (' + ddd_full_results['Phase'] + ')'

# Map to clean names
ddd_full_results['Label'] = ddd_full_results['Label'].replace({
    'Retail (Impl)': 'Retail Trade (Impl.)',
    'Retail (Post)': 'Retail Trade (Post)',
    'Food (Impl)': 'Food Services (Impl.)',
    'Food (Post)': 'Food Services (Post)'
})

# Sort for better plotting order
ddd_full_results = ddd_full_results.sort_values(by=['Sector', 'Phase'], ascending=[True, True])

# Plot
plt.figure(figsize=(9, 6))
sns.set_style("whitegrid")

# Use horizontal error bars (Forest Plot Style)
plt.errorbar(
    x=ddd_full_results['Coefficient'],
    y=ddd_full_results['Label'],
    xerr=[
        ddd_full_results['Coefficient'] - ddd_full_results['CI_lower'],
        ddd_full_results['CI_upper'] - ddd_full_results['Coefficient']
    ],
    fmt='o',
    capsize=5,
    color='darkorange',
    ecolor='grey',
    markersize=8
)

plt.axvline(0, color='red', linestyle='--', linewidth=1, label='No Differential Effect (vs. Prof. Services)')

plt.title('Triple-Difference (DDD) Effects: Retail & Food vs. Professional Services')
plt.xlabel('DDD Coefficient Estimate (Log Change)')
plt.ylabel('Sector and Phase')
plt.legend()
plt.tight_layout()
plt.show()

# Determine significance (p-value check required, but for plotting, we can use CI bounds)
# Significant if CI does NOT cross zero
ddd_full_results['Significant'] = ((ddd_full_results['CI_lower'] > 0) | (ddd_full_results['CI_upper'] < 0))

plt.figure(figsize=(9, 6))
sns.set_style("whitegrid")

# Plot using Seaborn Barplot, with hue to distinguish phases
ax = sns.barplot(
    x='Label',
    y='Coefficient',
    hue='Significant',  # Use significance for color distinction
    data=ddd_full_results,
    palette={True: 'green', False: 'lightgray'}, # Customize colors
    dodge=False, # Important: disable dodge if you want simple bars
    alpha=0.8
)

# Overlay error bars (CI)
for index, row in ddd_full_results.iterrows():
    ax.errorbar(
        index,
        row['Coefficient'],
        yerr=[[row['Coefficient'] - row['CI_lower']], [row['CI_upper'] - row['Coefficient']]],
        fmt='none',
        capsize=5,
        color='black'
    )

plt.axhline(0, color='red', linestyle='--', linewidth=1)
plt.title('DDD Coefficients: Significance and Magnitude (vs. Prof. Services)')
plt.ylabel('DDD Coefficient Estimate (Log Change)')
plt.xlabel('Sector and Phase')
plt.xticks(rotation=45, ha='right')

# Remove the significance legend as it's often better to interpret CIs directly
ax.legend_.remove()
plt.tight_layout()
plt.show()

def save_model_summary_to_csv(res, filename, cluster_col='ZIP'):
    """
    Extracts key results (coef, std err, p-value, CIs) from a statsmodels
    result object and saves them to a CSV file.
    """
    # 1. Extract the core summary table
    results_df = pd.DataFrame({
        'Coefficient': res.params,
        'Std_Error': res.bse,
        'P_Value': res.pvalues
    })

    # 2. Add 95% Confidence Intervals
    conf_int = res.conf_int()
    results_df['CI_Lower_95'] = conf_int.iloc[:, 0]
    results_df['CI_Upper_95'] = conf_int.iloc[:, 1]

    # Reset index to make the variable name a column
    results_df = results_df.reset_index().rename(columns={'index': 'Variable'})

    # 3. Add model information (optional but helpful)
    results_df['R_Squared'] = res.rsquared
    results_df['Num_Observations'] = res.nobs
    results_df['Cluster_Variable'] = cluster_col # Assuming clustering by ZIP

    # Save the DataFrame to CSV
    results_df.to_csv(filename, index=False)

save_model_summary_to_csv(results_did['Log_Median_Value'], 'Log_Median_Value_DID_Summary.csv')

save_model_summary_to_csv(results_did['Log_HPI'], 'Log_Hpi_DID_Summary.csv')

save_model_summary_to_csv(results_did['Log_Business_Density'], 'Business_density_Value_DID_Summary.csv')

def plot_event_study(res, title, omitted_year=-1, color='blue'):
    """Plots the coefficients from a dynamic DID (Event Study) model."""
    # Find terms, accounting for Patsy's Q() quoting
    event_terms = [col for col in res.params.index if col.startswith('Q("Event_')]

    plot_df = pd.DataFrame({
        'Coefficient': res.params.loc[event_terms],
        'CI_lower': res.conf_int().loc[event_terms, 0],
        'CI_upper': res.conf_int().loc[event_terms, 1]
    }).reset_index()

    # Extract the relative year from the quoted term name: Q("Event_X") -> X
    plot_df['Rel_Year'] = plot_df['index'].str.extract(r'Q\("Event_([-\d]+)"\)').astype(int)

    # Insert the omitted year (baseline)
    omitted_data = pd.DataFrame({'Rel_Year': [omitted_year], 'Coefficient': [0.0], 'CI_lower': [0.0], 'CI_upper': [0.0]})
    plot_df = pd.concat([plot_df, omitted_data], ignore_index=True)
    plot_df = plot_df.sort_values(by='Rel_Year').reset_index(drop=True)

    # Plot
    plt.figure(figsize=(10, 6))
    sns.set_style("whitegrid")

    plt.errorbar(
        plot_df['Rel_Year'],
        plot_df['Coefficient'],
        yerr=[
            plot_df['Coefficient'] - plot_df['CI_lower'],
            plot_df['CI_upper'] - plot_df['Coefficient']
        ],
        fmt='o', color=color, ecolor='gray', capsize=4, markersize=6
    )

    # Add lines for reference and treatment start
    plt.axhline(0, color='red', linestyle='--', linewidth=1)
    plt.axvline(omitted_year, color='green', linestyle=':', label=f'Omitted Baseline ({impl_start_year + omitted_year})')
    plt.axvline(omitted_year + 1, color='orange', linestyle='-', linewidth=1, label=f'Treatment Start ({impl_start_year})')

    plt.title(f'Dynamic DID (Event Study): {title}')
    plt.xlabel('Years Relative to Treatment Start (2009)')
    plt.ylabel('Coefficient (Change in Log Value)')
    plt.legend()
    plt.tight_layout()
    plt.show()

treatment_year = 2009
omitted_year = -1
df['Rel_Year'] = df['Year'] - treatment_year
formula_terms = []

for year in sorted(df['Rel_Year'].unique()):
    if year != omitted_year:
        col_name = f'Event_{year}'
        df[f'Rel_Year_{year}'] = (df['Rel_Year'] == year).astype(int)
        df[col_name] = df[f'Rel_Year_{year}'] * df['Treatment_Group']
        # Use Q() for Patsy to handle negative years
        formula_terms.append(f'Q("{col_name}")')

event_terms_formula = ' + '.join(formula_terms)
dynamic_base_formula = f'{event_terms_formula} + {controls} + C(ZIP) + C(Year)'

# Dynamic DID Model Fitting and Plotting
dynamic_outcomes = {
    'Log_Median_Value': 'blue',
    'Log_HPI': 'purple',
    'Log_Business_Density': 'teal'
}

print("\n Dynamic DID (Event Study)")
for dep_var, color in dynamic_outcomes.items():
    dynamic_formula = f'{dep_var} ~ {dynamic_base_formula}'
    res_dynamic = fit_ols_cluster(dynamic_formula, df)
    print(f"\nDynamic DID Results: {dep_var} ===")
    print(res_dynamic.summary())
    plot_event_study(res_dynamic, dep_var, color=color)