# capstone-data-analytics
Final Capstone Projects for Data Analytics Course

## PROJECT OVERVIEW: ECONOMIC IMPACT IN MARICOPA COUNTY
This repository contains two interconnected projects examining economic and business development factors within Maricopa County, Arizona, at the ZIP code level. The primary focus is understanding the economic effects of major transit infrastructure (specifically the Phoenix Light Rail) and underlying business density trends.

# PROJECT FOCUS AREAS
## Phoenix Light Rail Study:

### Goal: 
Examines the effect of the Phoenix Light Rail on housing and business density and sector change.

### Methodology: 
Difference-in-Differences (DiD) regression.

#### Note: 
This project is noted for having limitations in its current modeling and data preparation, particularly concerning the definition of control and treatment areas.

## Business Density Analysis:

### Goal: 
Investigates whether business density is primarily driven by historical trends or if current economic conditions play a more significant role.

### Purpose: 
This serves as a foundational analysis to better understand the variables used in the first study.

## REPRODUCTION GUIDE: RECREATING THE ANALYSIS
### Data preparation
The data preparation for these projects was executed using PySpark within the Google Colab environment. To reproduce the final master dataset and run the analysis, follow the steps below in the specified order.

NOTE: Ensure you have access to a PySpark environment (such as Google Colab or a local setup) to run the data preparation scripts.

STEP 1: PREPARE COUNTRY BUSINESS PATTERNS (CBP) DATA
This step combines granular business data into a usable format.

Navigate to the 'master_dataset/CBP_Data_Final' folder.

Access the input data located in the 'CBP_idn_Details' folder and the 'geonames postal code data file'.

Run the appropriate script (.py or .IPYNB) within this folder. This script combines the CBP data with the geonames postal code information.

STEP 2: PREPARE ZILLOW HOUSING DATA
This step cleans and combines raw housing data from multiple sources.

Go to the 'Housing_Data' folder.

Run the first script to clean and pivot the raw Zillow housing data.

Run the second script to combine the cleaned Zillow data with the Housing Index data.

STEP 3: CLEAN LIGHT RAIL DATA
This step processes the light rail station data and proximity features.

Navigate to the 'Light_Rail_Data' folder.

Run the script in this folder to clean and prepare the light rail data.

Output Note: This script produces two intermediate files, but only one, 'houseDataComplete', is needed for the final master dataset creation.

STEP 4: CREATE THE FINAL MASTER DATASET
This final step combines all prepared data sources into the primary analytical dataset.

Go to the main 'master_dataset' folder.

Run the script located here to combine the outputs from the previous steps.

Input Files: Before running the final script, ensure the following processed files are accessible in the environment:

combined_CDPDara_2000-23 (from Step 1)

houseDataComplete (from Step 3)

zip_rail_Proximity_Features (from Step 3)

USA_Zip_Codes

The final analytical dataset, named 'Final_lightRail_dataset', can be found in each projects folder and is used for the regression analysis.

### Phoenix Light Rail Study:
This project examines the economic effects of the Phoenix Light Rail.

Files Included:
Capstone Report (Final Paper)

Images (Visualizations included in the report)

Power BI Dashboard (Interactive visualizations)

Analysis Script: The script needed to run the Difference-in-Differences (DiD) analysis.

#### How to Run the Analysis:

Navigate to the 'Light_Rail_Study' folder.

Ensure the necessary input file, 'Final_lightRail_dataset', is present in the folder (as created in Step 4 of the Reproduction Guide).

Open the analysis script and execute the cells.

Output:
The script produces the following outputs within the project folder:

Results: Statistical results and tables, saved in the 'results' folder.

Visualizations: Image files generated by the script, saved in the 'images' folder.

### Business Density Analysis:
This project investigates the factors driving business density and uses a machine learning approach.

Files Included:
Supplemental Capstone Report

Images

Power BI Dashboard

Analysis Script: The script is named 'business_density_random_forest'.

#### How to Run the Analysis:

Navigate to the 'Business_Density_Folder'.

Run the 'business_density_random_forest' script.

The script first performs a preprocessing step on the 'Final_lightRail_dataset' to create a data subset.

Intermediate Step: This preprocessing step produces an intermediate file called 'Business Sector'.

The script then runs the full analysis, consisting of:

An OLS Regression.

A Random Forest Regression.

Output:
The script generates the final regression results and associated visualizations (images).

## Note:
EXECUTION ENVIRONMENT NOTE
All data preparation and analysis scripts were developed and executed in a Google Colab environment over several months. Many scripts rely on files created and immediately reused within the same execution session.

To ensure smooth operation and accurate replication of results, we strongly recommend running the scripts within a Google Colab environment. If you choose to use a different environment (e.g., local PySpark), adjustments to file paths and environment configurations will likely be required.

## File structure:
* **.gitattributes**
* **README.md**
* **BusinessDensity/**
    * *BusinessDensity.pbix* (Power BI Desktop File)
    * *Business_Density_Random_Forest.ipynb* (Random Forest Model Notebook)
    * *business_density_random_forest.py* (Python Script for RF Model)
    * *Final_lightRail_dataset.csv* (Input Data)
    * *Supplemental Capstone Report.docx* (Report Documentation)
    * **Bussines Density results/**
        * *Business_Sector.csv*
        * *model_metrics_summary.csv*
        * *ols_predictions_and_residuals.csv*
        * *rf_feature_importances.csv* (Feature Importance Results)
        * *sector_change_analysis.csv*
        * *zip_change_analysis.csv*
    * **Images/**
        * *Heatmap.png*
        * *OLS Results.png*
        * *Rf Results.png*
        * *Top Five Zip codes.png*
* **LightRailStudy/**
    * *Capstone Report.docx* (Main Report Documentation)
    * *DIDRegression.ipynb* (Difference-in-Differences Regression Notebook)
    * *didregression.py* (Python Script for DiD Model)
    * *Final_lightRail_dataset.csv* (Input Data)
    * *LightRail_Dashbroad.pbix* (Power BI Dashboard)
    * **images/**
        * *(Contains various coefficient plots, parallel trends charts, and scatter plots related to business density and housing price index)*
    * **light rail results/**
        * *A1_Coefficients.csv*
        * *B_Coefficients.csv*
        * *DID_Log_Business_Density_Full_Results.csv*
        * *DID_Log_HPI_Full_Results.csv*
        * *DID_Log_Median_Value_Full_Results.csv*
* **master_dataset/**
    * *Combined_CBPData_2000-23.csv* (Final Master Business Data)
    * *housingDataComplete.csv* (Final Master Housing Data)
    * *masterDataset.ipynb* (Data Combination Notebook)
    * *masterdataset.py* (Python Script for Data Combination)
    * *USA_ZIP_Codes.csv*
    * *zip_rail_proximity_features.csv* (Zip code features derived from rail proximity)
    * **CBP__Data_Final/**
        * *CountyBusinessPatterns_Details.ipynb* (Notebook for processing raw CBP data)
        * **CBP_idn_Details/**
            * *zbp00detail.txt* through *zbp23detail.txt* (Raw Census Business Patterns data files)
    * **Housing_Data/**
        * *HousingData.csv*
        * *housingDataClean.ipynb* (Notebook for cleaning housing data)
        * *hpi_at_zip5.xlsx* (House Price Index data)
        * *Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv* (Zillow Home Value Index data)
    * **Light_Rail_Data/**
        * *LightRailData.ipynb* (Notebook for processing raw light rail data)
        * *ValleyMetroRailStations_....csv* (Raw Light Rail Station locations)

Author name: Chris Coker

