# -*- coding: utf-8 -*-
"""ZillowData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rPUAtrIb2KcGfZ56ZYs_PkxmrP-nx0Tl
"""

# Import statemants
import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("ZillowData").getOrCreate()

sc = spark.sparkContext

# Upload data
from google.colab import files
uploaded = files.upload()

df = spark.read.csv("Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv", header=True, inferSchema=True)

"""**Note**: Make sure to run the cell that creates the temporary view (`xtKIVhwOU5MQ`) before running the cell that queries it (`OgFh0bwZWG9H`)."""

df.printSchema()
df.show(5)
print(df.dtypes)

df.createOrReplaceTempView("my_data_table")

county_to_filter = 'AZ'
filtered_df = spark.sql(f"""
    SELECT *
    FROM my_data_table
    WHERE State = '{county_to_filter}'
    ORDER BY RegionName ASC
""")

filtered_df.show()

clean_all_df = filtered_df.na.drop()

clean_all_df.show()

clean_all_df.printSchema()

output_path = "HousingData.csv"
clean_all_df.coalesce(1).write.csv(
    path=output_path,
    header=True,
    mode="overwrite"
)